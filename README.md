
<div align="center">

# VeritasAI
### Advanced AI Content Detection System

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
![Python Version](https://img.shields.io/badge/python-3.9%2B-blue)
![React Version](https://img.shields.io/badge/react-19-61dafb)
![Build Status](https://img.shields.io/badge/build-passing-brightgreen)

> **"Verify Content Authenticity in Real-Time."**
>
> A professional, multi-layered AI detection system capable of identifying text generated by GPT-4, Claude, Gemini, and other LLMs.

[Overview](#-overview) â€¢ [Features](#-key-features) â€¢ [Architecture](#-system-architecture) â€¢ [API](#-api-documentation) â€¢ [Installation](#-installation-guide)

</div>

---

## ğŸš€ Overview

**VeritasAI** is a full-stack web application designed to help users distinguish between human-written and AI-generated text. Unlike simple classifiers, VeritasAI employs a robust **Tri-Layer Analysis Engine**:

1.  **Statistical Analysis**: Calculates _Perplexity_ and _Burstiness_ to detect the "uniformity" typical of AI.
2.  **Linguistic Patterns**: Analyzes sentence structure, readability scores (ARI), and vocabulary richness.
3.  **Deep Learning Model**: Utilizes a fine-tuned Transformer model (RoBERTa/GPT-2) for semantic classification.

<div align="center">
  <img src="assets/veritas-dashboard.png" alt="VeritasAI Dashboard" width="90%">
</div>

---

## âœ¨ Key Features

| Feature | Description |
| :--- | :--- |
| **Real-Time Analysis** | Instant probability scoring with sub-second latency. |
| **Deep Metrics** | Visual gauges for "Burstiness", "Perplexity", and more. |
| **Modern UI/UX** | Glassmorphism-based design using React 19 & Tailwind CSS 4. |
| **PDF Reports** | Generate professional verification certificates instantly. |
| **Privacy First** | No data is stored; all analysis happens in-memory. |

---

## ï¿½ Project Structure

A high-level overview of the codebase organization.

```text
VeritasAI/
â”œâ”€â”€ backend/                 # Python FastAPI Server
â”‚   â”œâ”€â”€ main.py              # Application Entry Point
â”‚   â”œâ”€â”€ requirements.txt     # Python Dependencies
â”‚   â””â”€â”€ venv/                # Virtual Environment (Generated)
â”‚
â”œâ”€â”€ frontend/                # React Application
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx          # Main Component
â”‚   â”‚   â”œâ”€â”€ components/      # UI Components (Header, Input, etc.)
â”‚   â”‚   â””â”€â”€ index.css        # Tailwind & Global Styles
â”‚   â”œâ”€â”€ package.json         # Node Dependencies
â”‚   â””â”€â”€ vite.config.ts       # Build Configuration
â”‚
â”œâ”€â”€ assets/                  # Static Images (Banner, Screenshot)
â”œâ”€â”€ start_all.bat            # One-click startup script (Windows)
â””â”€â”€ README.md                # Documentation
```

---

## ğŸ— System Architecture

The system operates on a client-server architecture designed for modularity and speed.

### The Tri-Layer Engine (Backend)
When text is submitted, it passes through three distinct analysis pipelines:

1.  **Metric Engine (`scipy`, `nltk`)**:
    *   **Perplexity**: Measures how "surprised" a model is by the text. Low perplexity = likely AI.
    *   **Burstiness**: Measures variation in sentence structure. Low burstiness = likely AI.

2.  **Linguistic Engine (`spaCy`)**:
    *   Parses syntax trees to find repetitive sentence structures and lack of vocabulary diversity commonly found in LLM outputs.

3.  **Transformer Engine (`torch`, `transformers`)**:
    *   Passes tokenized text through a pre-trained RoBERTa model finetuned for detection.
    *   Outputs a raw probability logit which is normalized to a 0-100% score.

---

## ğŸ“¡ API Documentation

The Backend exposes a RESTful API powered by FastAPI.

### `POST /predict`
Analyzes the provided text and returns detection metrics.

**Request Endpoint:**
```http
POST http://localhost:8000/predict
```

**Request Body:**
```json
{
  "text": "The quick brown fox jumps over the lazy dog."
}
```

**Response:**
```json
{
  "ai_probability": 0.02,
  "human_probability": 0.98,
  "metrics": {
    "perplexity": 45.2,
    "burstiness": 120.5,
    "readability_score": "Standard"
  },
  "verdict": "Likely Human"
}
```

---

## ï¿½ğŸ’» Technologies Used

<div align="center">

### Backend
![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)

### Frontend
![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)
![Vite](https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=white)
![TailwindCSS](https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white)

</div>

---

## ğŸ›  Installation Guide

### âš¡ Quick Install (TL;DR)
*For experienced developers.*

**Terminal 1: Backend**
```bash
cd backend
python -m venv venv
# Windows: venv\Scripts\activate | Mac/Linux: source venv/bin/activate
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

**Terminal 2: Frontend**
```bash
cd frontend
npm install
```

### ğŸ“ Detailed Setup

#### 1. Backend Setup (Python)

**Step 1a: Create & Activate Virtual Environment**
```bash
cd backend
python -m venv venv
```
*   **Windows:** `venv\Scripts\activate`
*   **Mac/Linux:** `source venv/bin/activate`

**Step 1b: Install Dependencies**
```bash
pip install -r requirements.txt
python -m spacy download en_core_web_sm
```

#### 2. Frontend Setup (Node.js)

**Step 2a: Install Packages**
```bash
cd frontend
npm install
```

---

## â–¶ Running the Application

### Option A: The "One-Click" Script (Windows)

1.  Run `start_all.bat` from the root directory.
2.  Wait for **two windows** to open.

### Option B: Manual Start

**Backend**: `cd backend` -> `venv\Scripts\activate` -> `python main.py`
**Frontend**: `cd frontend` -> `npm run dev`

---

## â“ Troubleshooting & FAQ

<details>
<summary><strong>Q: I see "Failed to fetch" error on the website.</strong></summary>
<br>
This means the Frontend cannot talk to the Backend.<br>
1. Ensure both terminal windows are open.<br>
2. Ensure Backend is running on port `8000`.
</details>

<details>
<summary><strong>Q: "pip" or "python" is not recognized.</strong></summary>
<br>
You likely didn't add Python to your system PATH. Reinstall Python and check <strong>"Add Python to PATH"</strong>.
</details>

<details>
<summary><strong>Q: The installation is stuck on `torch`.</strong></summary>
<br>
PyTorch is >2GB. It may take 5-10 minutes depending on your internet connection.
</details>

---

## ğŸ¤ Contributing & License

Contributions are welcome! This project is licensed under the **MIT License**.
